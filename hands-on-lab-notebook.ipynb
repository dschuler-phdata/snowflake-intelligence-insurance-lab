{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "45vdyqk6vxu223nmgknk",
   "authorId": "7187848783705",
   "authorName": "USER0",
   "authorEmail": "",
   "sessionId": "6b8a824d-3644-43e6-acf9-bfa7e96c1482",
   "lastEditTime": 1762220931781
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "# Snowflake Intelligence Hands-On Lab\n\nIn this session, you will learn how to:\n- Perform semantic modeling to enable text-to-sql conversion via Cortex Analyst\n- Build custom tools like web search\n- Create Cortex Agents that can use Cortex Analyst and custom tools\n- Use Snowflake Intelligence as a UI layer for Cortex Agents\n- Investigate Snowflake's built in observability for the agent"
  },
  {
   "cell_type": "markdown",
   "id": "ee9f318c-cb11-467b-8713-2bb6ac17049f",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "## Section 1: Data prep\n\nIn this section, we'll configure the necessary Snowflake objects and data to perform the rest of the hands on lab.\n\nFor our structured data, we'll use a simple star schema, mocking insurance data. Our model will be composed of the following tables:\n- fact_claims: our event table tracking claims that have taken place\n- dim_policies: contains our information about the various policies issued\n- dim_businesses: contains information about the various businesses that are insured"
  },
  {
   "cell_type": "code",
   "id": "b8a338d1-763d-4f8d-931e-bd63d384c964",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Get the username directly from the session\nuser_name = session.sql(\"SELECT CURRENT_USER()\").collect()[0][0]\nprint(user_name)\n\n# Construct the full schema path using an f-string\ntarget_schema = f\"CORTEX_LAB_DB_{user_name}.RISK_DATA_{user_name}\"\n\n# Execute the USE SCHEMA command\nsession.sql(f\"USE SCHEMA {target_schema}\").collect()\n\nprint(f\"Session context set to: {target_schema}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc7ff6ce-2c32-44a1-b6ac-63bd5cd1ccac",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "### 1.1 - Create tables"
  },
  {
   "cell_type": "code",
   "id": "94d2c454-78d0-4689-ab03-62b26c6854e7",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE DIM_BUSINESS (\n    BUSINESS_KEY INT PRIMARY KEY,\n    BUSINESS_NAME VARCHAR(255),\n    BUSINESS_CITY VARCHAR(100),\n    BUSINESS_STATE VARCHAR(2),\n    NAICS_CODE VARCHAR(10),\n    INDUSTRY_SEGMENT VARCHAR(100),\n    ASSET_VALUE_MILLIONS NUMERIC(10, 2)\n);\n\nCREATE OR REPLACE TABLE DIM_POLICY (\n    POLICY_KEY INT PRIMARY KEY,\n    BUSINESS_KEY INT REFERENCES DIM_BUSINESS (BUSINESS_KEY),\n    POLICY_ID VARCHAR(50),\n    POLICY_TYPE VARCHAR(50),\n    EFFECTIVE_DATE DATE,\n    EXPIRATION_DATE DATE,\n    POLICY_STATUS VARCHAR(20), \n    ANNUAL_PREMIUM_USD NUMERIC(12, 2),\n    PREMIUM_EARNED_USD NUMERIC(12, 2)\n);\n\nCREATE OR REPLACE TABLE FACT_CLAIMS (\n    POLICY_KEY INT REFERENCES DIM_POLICY (POLICY_KEY),\n    BUSINESS_KEY INT REFERENCES DIM_BUSINESS (BUSINESS_KEY),\n    CLAIM_ID VARCHAR(50),\n    CLAIM_DATE DATE,\n    LOSS_TYPE VARCHAR(100),\n    REPORTED_LAG_DAYS INT,\n    INCURRED_AMOUNT_USD NUMERIC(12, 2),\n    IS_CATASTROPHE BOOLEAN,\n    CLAIM_STATUS VARCHAR(20)\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7519bf3f-513d-4a78-89aa-bf54b39dcafc",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "### 1.2 - Insert data"
  },
  {
   "cell_type": "code",
   "id": "f2b7435b-0ec4-49c1-989d-064e941d4c17",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Populate DIM_BUSINESS (Local Cincinnati Focus)\nINSERT INTO DIM_BUSINESS (BUSINESS_KEY, BUSINESS_NAME, BUSINESS_CITY, BUSINESS_STATE, NAICS_CODE, INDUSTRY_SEGMENT, ASSET_VALUE_MILLIONS)\nVALUES\n(1, 'Deeper Roots Coffee', 'Cincinnati', 'OH', '722515', 'Restaurant & Hospitality', 2.50),\n(2, 'The Eagle OTR', 'Cincinnati', 'OH', '722511', 'Restaurant & Hospitality', 4.10),\n(3, 'Rhinegeist Brewery', 'Cincinnati', 'OH', '312120', 'Beverage Manufacturing', 45.00),\n(4, 'Cincinnati Zoo & Botanical Garden', 'Cincinnati', 'OH', '712130', 'Arts, Entertainment', 120.00),\n(5, 'Local Food Truck Corp.', 'Cincinnati', 'OH', '722330', 'Mobile Food Services', 0.85),\n(6, 'Queen City T-Shirt Printing', 'Cincinnati', 'OH', '323113', 'Small-Scale Manufacturing', 3.20),\n(7, 'The Lytle Park Hotel', 'Cincinnati', 'OH', '721110', 'Hospitality', 65.00),\n(8, 'Cincinnati Museum Center', 'Cincinnati', 'OH', '712110', 'Museums & Historical Sites', 95.50);\n\n-- Set the Current Date for the Demo: October 2025\n-- Policies 101 and 102 are expiring soon (next 30-60 days)\n\nINSERT INTO DIM_POLICY (POLICY_KEY, BUSINESS_KEY, POLICY_ID, POLICY_TYPE, EFFECTIVE_DATE, EXPIRATION_DATE, POLICY_STATUS, ANNUAL_PREMIUM_USD, PREMIUM_EARNED_USD)\nVALUES\n(101, 1, 'GL00101', 'General Liability', '2024-11-20', '2025-11-20', 'Active', 12000.00, 12000.00), -- Deeper Roots (Expiring Soon)\n(102, 2, 'GL00102', 'General Liability', '2024-11-20', '2025-11-20', 'Active', 18000.00, 18000.00), -- The Eagle OTR (Expiring Soon)\n(103, 3, 'PC00103', 'Commercial Property', '2025-01-01', '2026-01-01', 'Active', 55000.00, 45833.33),  -- Premium earned for 10 months\n(104, 4, 'WC00104', 'Workers Compensation', '2025-06-01', '2026-06-01', 'Active', 75000.00, 25000.00),  -- Premium earned for 4 months\n(105, 5, 'GL00105', 'General Liability', '2024-11-01', '2025-11-01', 'Active', 4500.00, 4500.00), -- Food Truck (Expiring Soon, but Low Risk)\n(106, 6, 'GL00106', 'General Liability', '2025-02-01', '2026-02-01', 'Active', 8500.00, 6375.00),  -- Premium earned for 9 months\n(107, 7, 'PC00107', 'Commercial Property', '2025-04-01', '2026-04-01', 'Active', 95000.00, 55416.67),  -- Premium earned for 7 months\n(108, 8, 'CY00108', 'Cyber Liability', '2025-01-01', '2026-01-01', 'Active', 15000.00, 12500.00);  -- Premium earned for 10 months\n\n-- Populate FACT_CLAIMS (Claims to create high loss ratio for local companies)\nINSERT INTO FACT_CLAIMS (POLICY_KEY, BUSINESS_KEY, CLAIM_ID, CLAIM_DATE, LOSS_TYPE, REPORTED_LAG_DAYS, INCURRED_AMOUNT_USD, IS_CATASTROPHE, CLAIM_STATUS)\nVALUES\n-- HIGH RISK: Deeper Roots Coffee (BUSINESS_KEY=1, POLICY_KEY=101) - LR = 1.50\n(101, 1, 'C10001', '2025-03-10', 'Slip & Fall', 1, 8000.00, FALSE, 'Closed'),\n(101, 1, 'C10002', '2025-05-05', 'Property Damage (burst pipe)', 3, 5500.00, FALSE, 'Closed'),\n(101, 1, 'C10003', '2025-08-25', 'Customer Injury (Hot beverage)', 1, 4500.00, FALSE, 'Open'),\n-- HIGH RISK: The Eagle OTR (BUSINESS_KEY=2, POLICY_KEY=102) - LR = 1.50\n(102, 2, 'C20001', '2025-01-05', 'Food Poisoning (Single incident)', 2, 10000.00, FALSE, 'Closed'),\n(102, 2, 'C20002', '2025-04-10', 'Liquor Liability', 10, 15000.00, FALSE, 'Open'),\n(102, 2, 'C20003', '2025-07-20', 'Theft (patio furniture)', 4, 2000.00, FALSE, 'Closed'),\n\n-- Other claims for context\n(103, 3, 'C30001', '2025-03-20', 'Minor Fire Damage', 7, 12000.00, FALSE, 'Closed'), -- Rhinegeist Brewery\n(104, 4, 'C40001', '2025-07-01', 'Workplace Minor Injury', 2, 5500.00, FALSE, 'Closed'), -- Cincinnati Zoo\n(105, 5, 'C50001', '2025-02-05', 'Vehicle Collision', 5, 2500.00, FALSE, 'Open'), -- Local Food Truck Corp.\n(106, 6, 'C60001', '2025-05-01', 'Equipment Failure', 3, 8000.00, FALSE, 'Open'), -- Queen City T-Shirt Printing\n(107, 7, 'C70001', '2025-08-03', 'Small Hail Damage', 2, 15000.00, FALSE, 'Open'), -- The Lytle Park Hotel\n(108, 8, 'C80001', '2025-09-10', 'System Ransomware', 1, 10000.00, FALSE, 'Open'); -- Cincinnati Museum Center",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "050e33f5-725f-4125-8d9a-a4ac72083b7c",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "### 1.3 - Run some sample queries"
  },
  {
   "cell_type": "code",
   "id": "1b6e74f4-b3fd-4c57-a109-c45ead0db5ad",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "-- Amount of loss incurred from claims for Commerical Property policies\nSELECT policy_type, sum(incurred_amount_usd)\nFROM fact_claims c\nJOIN dim_policy p\n  on c.policy_key = p.policy_key\nWHERE policy_type = 'Commercial Property'\nGROUP BY policy_type\n;\n\n-- Run some other queries!",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "327e5d60-987a-46e8-895d-950ea8e567f1",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "## Section 2: Cortex Analyst\n\nCortex Analyst is a fully managed, AI-powered feature in Snowflake to answer natural language queries about your structured data. It relies on a Semantic model to provide metadata and context about your relational data to the LLM so that it can generate SQL based on the question at hand.\n\nThe Semantic Layer can be defined as a YAML file or as a Semantic View - a new schema-level object in Snowflake.\n"
  },
  {
   "cell_type": "markdown",
   "id": "3a8e2820-fe5c-4e20-9fab-2fbfe946521c",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "### 2.1 - Semantic Views\nSemantic Views are schema-level objects in Snowflake that enable us to define business metrics, entities, and their relationships. This context will be leveraged by Cortex Analyst for generating SQL to answer natural language questions.\n\nSemantic Views are comprised of the following components:\n\n- **Tables**: logical tables that map to Snowflake tables or views\n- **Facts**: row-level attributes tied to a logical table that represent specific business events or transactions\n- **Dimensions**: categorical attributes tied to a logical table that gives meaning to metrics by grouping data into meaningful categories\n- **Metrics**: quantifiable measures of business performance calculated by aggregating facts or other columns from the same table\n**Named filters**: logic to filter a logical table based on some business rule\n**Relationships**: how logical tables are mapped to one another. This enables Cortex Analyst to join multiple logical tables together\n\nSemantic Views can be created through SQL (as seen below), but also through the Snowsight UI which is what we'll walk through together in this lab."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "-- -- Semantic View SQL - We will create this together via the UI\ncreate or replace semantic view RISK_SEMANTIC_VIEW tables (\n    DIM_BUSINESS primary key (BUSINESS_KEY) comment = 'This table stores information about businesses, including a unique identifier, name, location, industry classification (e.g., Restaurant & Hospitality), and financial data, to support business intelligence and analytics.',\n    DIM_POLICY primary key (POLICY_KEY) comment = 'This table stores information about insurance policies. CRITICAL FIELDS: POLICY_STATUS (\"Active\"), EXPIRATION_DATE (to check for upcoming renewals), and PREMIUM_EARNED_USD (for Loss Ratio calculation).',\n    FACT_CLAIMS primary key (CLAIM_ID) comment = 'This table stores information about insurance claims, including the policy and business keys, incurred amount, and claim status. CLAIM_ID is the unique identifier for a claim.'\n) relationships (\n    CLAIMS_TO_POLICIES as FACT_CLAIMS(POLICY_KEY) references DIM_POLICY(POLICY_KEY),\n    CLAIMS_TO_BUSINESSES as FACT_CLAIMS(BUSINESS_KEY) references DIM_BUSINESS(BUSINESS_KEY)\n) facts (\n    DIM_BUSINESS.ASSET_VALUE_MILLIONS as ASSET_VALUE_MILLIONS comment = 'The total value of assets held by the business, expressed in millions of dollars.',\n    DIM_BUSINESS.BUSINESS_KEY as BUSINESS_KEY comment = 'Unique identifier for a business entity.',\n    DIM_POLICY.ANNUAL_PREMIUM_USD as ANNUAL_PREMIUM_USD comment = 'The total annual premium amount paid by policyholders in US dollars.',\n    DIM_POLICY.PREMIUM_EARNED_USD as PREMIUM_EARNED_USD comment = 'The portion of the premium that has been recognized as revenue, critical for calculating accurate Loss Ratio (Incurred Claims / Earned Premium).',\n    DIM_POLICY.POLICY_KEY as POLICY_KEY comment = 'Unique identifier for a policy in the insurance portfolio.',\n    FACT_CLAIMS.BUSINESS_KEY as BUSINESS_KEY comment = 'Unique identifier for a business entity, links claims to business.',\n    FACT_CLAIMS.CLAIM_ID as CLAIM_ID comment = 'Unique identifier for a claim submitted by a customer.',\n    FACT_CLAIMS.INCURRED_AMOUNT_USD as INCURRED_AMOUNT_USD comment = 'The total amount of financial loss incurred for a claim, expressed in US dollars. Used as the numerator in the Loss Ratio calculation.',\n    FACT_CLAIMS.POLICY_KEY as POLICY_KEY comment = 'Unique identifier for a policy, links claims to policy details.',\n    FACT_CLAIMS.REPORTED_LAG_DAYS as REPORTED_LAG_DAYS comment = 'The number of days between the date an incident occurred and the date it was reported.'\n) dimensions (\n    DIM_BUSINESS.BUSINESS_CITY as BUSINESS_CITY comment = 'The city where the business is located. Example: Cincinnati.',\n    DIM_BUSINESS.BUSINESS_NAME as BUSINESS_NAME comment = 'The name of the business or organization.',\n    DIM_BUSINESS.BUSINESS_STATE as BUSINESS_STATE comment = 'The state in which the business is located.',\n    DIM_BUSINESS.INDUSTRY_SEGMENT as INDUSTRY_SEGMENT comment = 'The industry segment in which the business operates, such as Restaurant & Hospitality, Beverage Manufacturing, or Arts, Entertainment.',\n    DIM_BUSINESS.NAICS_CODE as NAICS_CODE comment = 'Industry Classification Code.',\n    DIM_POLICY.EFFECTIVE_DATE as EFFECTIVE_DATE comment = 'The date when a policy becomes effective.',\n    DIM_POLICY.EXPIRATION_DATE as EXPIRATION_DATE comment = 'Date on which the policy expires. Use this to find policies due for renewal soon (e.g., within 60 days of today).',\n    DIM_POLICY.POLICY_ID as POLICY_ID comment = 'Unique identifier for a policy.',\n    DIM_POLICY.POLICY_STATUS as POLICY_STATUS comment = 'The current status of the policy. Must be \"Active\" to be included in current risk reviews.',\n    DIM_POLICY.POLICY_TYPE as POLICY_TYPE comment = 'Type of insurance policy held by the customer, such as General Liability, Commercial Property, or Workers Compensation.',\n    FACT_CLAIMS.CLAIM_DATE as CLAIM_DATE comment = 'Date on which the claim was made.',\n    FACT_CLAIMS.CLAIM_STATUS as CLAIM_STATUS comment = 'The current status of a claim, indicating whether it is Open or Closed.',\n    FACT_CLAIMS.IS_CATASTROPHE as IS_CATASTROPHE comment = 'Indicates whether the claim is related to a catastrophic event.',\n    FACT_CLAIMS.LOSS_TYPE as LOSS_TYPE comment = 'The type of loss or damage that occurred.'\n) with extension (\n    CA = '{\"tables\":[{\"name\":\"DIM_BUSINESS\",\"dimensions\":[{\"name\":\"BUSINESS_CITY\",\"sample_values\":[\"Cincinnati\"]},{\"name\":\"BUSINESS_NAME\",\"sample_values\":[\"Deeper Roots Coffee\",\"The Eagle OTR\",\"Rhinegeist Brewery\"]},{\"name\":\"BUSINESS_STATE\",\"sample_values\":[\"OH\"]},{\"name\":\"INDUSTRY_SEGMENT\",\"sample_values\":[\"Restaurant & Hospitality\",\"Beverage Manufacturing\",\"Arts, Entertainment\"]},{\"name\":\"NAICS_CODE\",\"sample_values\":[\"722515\",\"722511\",\"312120\"]}],\"facts\":[{\"name\":\"ASSET_VALUE_MILLIONS\",\"sample_values\":[\"2.50\",\"4.10\",\"45.00\"]},{\"name\":\"BUSINESS_KEY\",\"sample_values\":[\"1\",\"2\",\"3\"]}]},{\"name\":\"DIM_POLICY\",\"dimensions\":[{\"name\":\"POLICY_ID\",\"sample_values\":[\"GL00101\",\"GL00102\",\"PC00103\"]},{\"name\":\"POLICY_TYPE\",\"sample_values\":[\"General Liability\",\"Commercial Property\"]},{\"name\":\"POLICY_STATUS\",\"sample_values\":[\"Active\",\"Inactive\"]}],\"facts\":[{\"name\":\"ANNUAL_PREMIUM_USD\",\"sample_values\":[\"12000.00\",\"18000.00\",\"55000.00\"]},{\"name\":\"PREMIUM_EARNED_USD\",\"sample_values\":[\"12000.00\",\"18000.00\",\"45833.33\"]},{\"name\":\"POLICY_KEY\",\"sample_values\":[\"101\",\"102\",\"103\"]}],\"time_dimensions\":[{\"name\":\"EFFECTIVE_DATE\",\"sample_values\":[\"2024-11-01\",\"2024-10-25\",\"2025-01-01\"]},{\"name\":\"EXPIRATION_DATE\",\"sample_values\":[\"2025-11-01\",\"2025-10-25\",\"2026-01-01\"]}]},{\"name\":\"FACT_CLAIMS\",\"dimensions\":[{\"name\":\"CLAIM_STATUS\",\"sample_values\":[\"Open\",\"Closed\"]},{\"name\":\"IS_CATASTROPHE\",\"sample_values\":[\"FALSE\"]},{\"name\":\"LOSS_TYPE\",\"sample_values\":[\"Slip & Fall\",\"Liquor Liability\",\"Food Poisoning\"]}],\"facts\":[{\"name\":\"BUSINESS_KEY\",\"sample_values\":[\"1\",\"2\",\"3\"]},{\"name\":\"CLAIM_ID\",\"sample_values\":[\"C10003\",\"C20002\",\"C10001\"]},{\"name\":\"INCURRED_AMOUNT_USD\",\"sample_values\":[\"4500.00\",\"15000.00\",\"8000.00\"]},{\"name\":\"POLICY_KEY\",\"sample_values\":[\"101\",\"102\",\"103\"]},{\"name\":\"REPORTED_LAG_DAYS\",\"sample_values\":[\"1\",\"10\",\"3\"]}],\"time_dimensions\":[{\"name\":\"CLAIM_DATE\",\"sample_values\":[\"2025-08-25\",\"2025-04-10\",\"2025-03-10\"]}]}],\"relationships\":[{\"name\":\"CLAIMS_TO_POLICIES\"},{\"name\":\"CLAIMS_TO_BUSINESSES\"}]}'\n);\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b3f2f87b-0c7e-4205-8ee0-691a2368c558",
   "metadata": {
    "language": "sql",
    "name": "cell12",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Verify Semantic View\nSHOW SEMANTIC VIEWS;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8666928d-85ad-43b3-bf12-c381443910bb",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "### 2.2 - Creating our first Cortex Agent\nNow that we have a Semantic View created for use with Cortex Analyst, we can create a Cortex Agent that will be able to answer natural language questions about our data.\n\nCortex Agents are the brains of this demo. Agents will orchestrate both structured and unstructured data to deliver insights. They plan tasks, use tools to execute these tasks, and generate responses. Agents can be configured to use Cortex Analyst (structured data), Cortex Search (unstructured data), and custom tools to generate answers.\n\n"
  },
  {
   "cell_type": "code",
   "id": "bd629ccc-3ee2-4e88-8f60-fe3c97c8f51a",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": "unique_agent_name = f\"Company_Chatbot_Agent_Structured_{user_name}\"\n\n# 2. Define the PROFILE clause content separately to avoid f-string nesting errors\nprofile_content = '{\"display_name\": \"1. Risk Analysis Agent - Structured Data\"}'\n\n# 3. Construct the full CREATE AGENT SQL using an f-string\ncreate_agent_sql = f\"\"\"\n    CREATE OR REPLACE AGENT SNOWFLAKE_INTELLIGENCE.AGENTS.{unique_agent_name}\n    WITH PROFILE='{profile_content}'\n    COMMENT=$$ This is an agent that can answer questions about our insurance data including policies, businesses, and claims. $$\n    FROM SPECIFICATION $$\n    {{\n      \"models\": {{\n        \"orchestration\": \"\"\n      }},\n      \"instructions\": {{\n        \"response\": \"You are a data analyst who has access to insurance policies, insured businesses, and claims. If user does not specify a date range assume it for year 2025. Leverage data from all domains to analyse & answer user questions. Provide visualizations if possible. Trendlines should default to linecharts, Categories default to Barchart.\",\n        \"orchestration\": \"Use cortex analyst for any questions regarding the policies, businesses, and claims data.\\\\n\\\\n\\\\n\",\n        \"sample_questions\": [\n          {{\n            \"question\": \"What has been our incurred loss by category over the last 12 months?\"\n          }}\n        ]\n      }},\n      \"tools\": [\n        {{\n          \"tool_spec\": {{\n            \"type\": \"cortex_analyst_text_to_sql\",\n            \"name\": \"Query Insurance Datamart\",\n            \"description\": \"Allows users to query finance data for a company in terms of revenue & expenses.\"\n          }}\n        }}\n      ],\n      \"tool_resources\": {{\n        \"Query Insurance Datamart\": {{\n          \"semantic_view\": \"CORTEX_LAB_DB_{user_name}.RISK_DATA_{user_name}.RISK_SEMANTIC_VIEW\",\n          \"execution_environment\": {{\n              \"query_timeout\": 0,\n              \"type\": \"warehouse\",\n              \"warehouse\": \"LAB_WH_{user_name}\"\n          }},\n        }}\n      }}\n    }}\n    $$;\n\"\"\"\n\n# 4. Execute the dynamically created SQL command\nsession.sql(create_agent_sql).collect()\n\nprint(f\"Agent created successfully: {unique_agent_name}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f94ccb0f-d6cb-47ae-b9ad-41b3c80e6de9",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "### 2.3 Test Analyst Agent v1!\n\nOpen Snowflake Intelligence by clicking on 'AI & ML' on the left navbar and then choosing 'Snowflake Intelligence'.\n\nOnce there, ask away about our structured data! Here are some sample questions as thought starters:\n\n- What was our incurred loss amount by policy type over the last 12 months?\n- How many claims have been made over the last 3 months? \n"
  },
  {
   "cell_type": "markdown",
   "id": "038159ca-458e-4957-9d9c-0f7e1470553f",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "## Section 3: Custom Tools\n\nIn addition to Cortex Analyst and Cortex Search, we can also equip our agent with custom tools for execution. In this section, we'll create additional tools for sending emails and performing web search."
  },
  {
   "cell_type": "markdown",
   "id": "d5bd4830-abdd-45bd-b8d7-479409ee47de",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "### 3.2 Web Search Tool\nWe can also create functions using python and make those available as tools to the agent. The code below creates a simple web search function that can be used by our agent for getting additional information from the web."
  },
  {
   "cell_type": "code",
   "id": "5270a7b9-a380-49c3-a25d-abc30a72fba3",
   "metadata": {
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION Web_search(search_query STRING)\nRETURNS VARIANT\nLANGUAGE PYTHON\nRUNTIME_VERSION = 3.11\nARTIFACT_REPOSITORY = snowflake.snowpark.pypi_shared_repository\nHANDLER = 'web_search'\nEXTERNAL_ACCESS_INTEGRATIONS = (Snowflake_intelligence_ExternalAccess_Integration)\nPACKAGES = ('tavily-python')\nAS\n$$\nfrom tavily import TavilyClient\n\ndef web_search(search_query: str):\n    try:\n        TAVILY_API_KEY = \"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\"  # Replace with your real key\n        tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n\n        response = tavily_client.search(\n            query=search_query,\n            max_results=5,\n            include_answer=True\n        )\n\n        results = response.get(\"results\", [])\n        if not results:\n            return {\"summary\": \"No results found.\", \"results\": []}\n\n        formatted_results = []\n        for i, result in enumerate(results[:3]):\n            formatted_results.append({\n                \"rank\": i + 1,\n                \"title\": result.get(\"title\", \"Untitled\"),\n                \"url\": result.get(\"url\", \"\"),\n                \"snippet\": result.get(\"content\", \"\").strip()[:1500]\n            })\n\n        return {\n            \"summary\": response.get(\"answer\", \"\"),\n            \"results\": formatted_results\n        }\n\n    except Exception as e:\n        return {\"error\": str(e)}\n$$;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3519ba9d-c540-4e72-b0e3-512a5e553173",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "### 3.3 Update the Agent with tools\nNow that we have the tools defined, we can recreate our agent to give it the ability to call the tools."
  },
  {
   "cell_type": "code",
   "id": "04ccdea3-440b-4f49-ad46-48b9f046887b",
   "metadata": {
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": "unique_agent_name = f\"Company_Chatbot_Agent_Tools_{user_name}\"\n\n# 3. Construct the full CREATE AGENT SQL using an f-string\ncreate_agent_sql = f\"\"\"\n    CREATE OR REPLACE AGENT SNOWFLAKE_INTELLIGENCE.AGENTS.{unique_agent_name}\n    WITH PROFILE='{{\"display_name\": \"2. Risk Analysis Agent - Tools\"}}'\n    COMMENT=$$ This is an agent that can answer questions about our insurance data including policies, businesses, and claims and has access to web search via tools. $$\n    FROM SPECIFICATION $$\n{{  \n  \"models\": {{\n    \"orchestration\": \"\"\n  }},\n  \"instructions\": {{\n      \"response\": \"You are a data analyst who has access to insurance policies, insured businesses, and claims. If the user does not specify a date range, assume it is for the year 2025. Leverage data from all domains to analyze and answer user questions. Provide visualizations if possible. Trendlines should default to line charts, categories default to bar charts. You have access to a Web_search tool that returns structured results, including 'title', 'url', and 'snippet'. When using the Web_search tool, always: 1. Include a short summary of your findings. 2. List the sources using markdown links in the format [title](url) so the user can validate the content. 3. Include at least 2 sources whenever possible. 4. If no results are found, clearly state 'No results found.' Do not make up URLs or sources â€” only use those returned by the Web_search tool.\",\n    \"orchestration\": \"Use cortex analyst for any questions regarding the policies, businesses, and claims data.\\\\n\\\\n\\\\n\",\n    \"sample_questions\": [\n      {{\n        \"question\": \"What was our incurred loss amount by policy type over the last 12 months?\"\n      }}\n    ]\n  }},\n  \"tools\": [\n    {{\n      \"tool_spec\": {{\n        \"type\": \"cortex_analyst_text_to_sql\",\n        \"name\": \"Query Insurance Datamart\",\n        \"description\": \"Allows users to query finance data for a company in terms of revenue & expenses.\"\n      }}\n    }},\n    {{\n      \"tool_spec\": {{\n        \"type\": \"generic\",\n        \"name\": \"Web_search\",\n        \"description\": \"Search the web for recent or relevant information about a topic.\",\n        \"input_schema\": {{\n          \"type\": \"object\",\n          \"properties\": {{\n            \"search_query\": {{\n              \"description\": \"The user-provided search query.\",\n              \"type\": \"string\"\n            }}\n          }},\n          \"required\": [\"search_query\"]\n        }}\n      }}\n    }},\n    {{\n      \"tool_spec\": {{\n        \"type\": \"generic\",\n        \"name\": \"Send_Emails\",\n        \"description\": \"This tool is used to send emails to a email recipient. It can take an email, subject & content as input to send the email. Always use HTML formatted content for the emails.\",\n        \"input_schema\": {{\n          \"type\": \"object\",\n          \"properties\": {{\n            \"recipient\": {{\n              \"description\": \"recipient of email\",\n              \"type\": \"string\"\n            }},\n            \"subject\": {{\n              \"description\": \"subject of email\",\n              \"type\": \"string\"\n            }},\n            \"text\": {{\n              \"description\": \"content of email\",\n              \"type\": \"string\"\n            }}\n          }},\n          \"required\": [\n            \"text\",\n            \"recipient\",\n            \"subject\"\n          ]\n        }}\n      }}\n    }}\n  ],\n  \"tool_resources\": {{\n    \"Query Insurance Datamart\": {{\n      \"semantic_view\": \"CORTEX_LAB_DB_{user_name}.RISK_DATA_{user_name}.RISK_SEMANTIC_VIEW\",\n      \"execution_environment\": {{\n          \"query_timeout\": 0,\n          \"type\": \"warehouse\",\n          \"warehouse\": \"LAB_WH_{user_name}\"\n      }},\n    }},\n    \"Web_search\": {{\n      \"execution_environment\": {{\n        \"query_timeout\": 0,\n        \"type\": \"warehouse\",\n        \"warehouse\": \"LAB_WH_{user_name}\"\n      }},\n      \"identifier\": \"CORTEX_LAB_DB_{user_name}.RISK_DATA_{user_name}.WEB_SEARCH\",\n      \"name\": \"WEB_SEARCH(VARCHAR)\",\n      \"type\": \"function\"\n    }}\n  }}\n}}\n$$;\n\"\"\"\n\n# 4. Execute the dynamically created SQL command\nsession.sql(create_agent_sql).collect()\n\nprint(f\"Agent created successfully: {unique_agent_name}\")\n# print(create_agent_sql) # Uncomment to inspect the final SQL string",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5b13c32b-613f-47a2-a81c-c00e92107d75",
   "metadata": {
    "name": "cell23",
    "collapsed": false
   },
   "source": "### 3.4 Test the updated agent\n\nOne sample flow (ask all questions in one conversation):\n- Show me all active General Liability policies for our clients in Cincinnati's Restaurant & Hospitality sector with a Loss Ratio above 1.4 that are due for renewal soon. Calculate the Loss Ratio.\n- Start with The Eagle OTR. Use the web search tool to find any recent news or regulatory actions related to health code violations or labor issues in Cincinnati.\n- Combine the internal policy data (loss ratio) with the external web search findings and provide a final renewal recommendation for The Eagle OTR. Justify your score."
  },
  {
   "cell_type": "markdown",
   "id": "849ec522-1ebf-4f6e-b2ae-e1fe07164ee7",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "## Section 4: AI Observability\n\nAfter asking a few questions to our agent, we can explore Snowflake's built in AI Observability tooling to understand what tools were invoked to accomplish the given tasks.\n\nStart by clicking on 'AI & ML' on the left hand havbar, and then opening 'Cortex Agents' in a new tab. Once on the Cortex Agents screen, choose the 'COMPANY_CHATBOT_AGENT_TOOLS' agent. Here, you can see all of the configuration for our agent, including which tools it has available.\n\nNext, click on 'Monitoring' and then choose one of your conversations. This is where we can see all the detail going on behind the scenes. Find a task that used Cortex Analyst - there we can see the exact SQL that was generated and executed to answer the given question. On the 'Web search' tasks, we can see the given prompt and the web search results that was fed back to the model."
  }
 ]
}